{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":81739,"sourceType":"datasetVersion","datasetId":6776}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:30:33.044326Z","iopub.execute_input":"2025-03-26T14:30:33.044755Z","iopub.status.idle":"2025-03-26T14:30:36.432933Z","shell.execute_reply.started":"2025-03-26T14:30:33.044697Z","shell.execute_reply":"2025-03-26T14:30:36.432058Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os\n\n# Define valid characters\nvalid_chars = set(\"abcdefghijklmnopqrstuvwxyz0123456789 .,?!'-\")\nprint(f\"Valid characters: {sorted(list(valid_chars))}, Total: {len(valid_chars)}\")\n\n# Define the directory containing the lyrics files\nlyrics_dir = '/kaggle/input/poetry/'\n\n# Load all lyrics files into a list of cleaned songs\nsongs = []\nfor filename in os.listdir(lyrics_dir):\n    if filename.endswith('.txt'):\n        file_path = os.path.join(lyrics_dir, filename)\n        with open(file_path, 'r', encoding='utf-8') as f:\n            lyrics = f.read().lower()\n            # Filter out invalid characters\n            cleaned_lyrics = ''.join(ch for ch in lyrics if ch in valid_chars)\n            if cleaned_lyrics:  # Only add non-empty songs\n                songs.append(cleaned_lyrics)\n\nprint(f\"Loaded {len(songs)} songs\")\n\n# Create vocabulary from valid characters in songs\nall_chars = set()\nfor song in songs:\n    all_chars.update(song)\nchars = sorted(list(all_chars))\nchar_to_idx = {ch: i for i, ch in enumerate(chars)}\nidx_to_char = {i: ch for i, ch in enumerate(chars)}\nvocab_size = len(chars)\nprint(f\"Vocabulary size: {vocab_size}, Characters: {chars}\")\n\n# Encode each song and create sequences\nsequence_length = 50\nsequences = []\ntargets = []\nfor song in songs:\n    encoded_song = [char_to_idx[ch] for ch in song]\n    # Only create sequences within this song\n    for i in range(0, len(encoded_song) - sequence_length):\n        seq = encoded_song[i:i + sequence_length]\n        target = encoded_song[i + 1:i + sequence_length + 1]\n        sequences.append(seq)\n        targets.append(target)\n\n# Convert to PyTorch tensors\nsequences = torch.tensor(sequences, dtype=torch.long)\ntargets = torch.tensor(targets, dtype=torch.long)\n\n# Custom Dataset\nclass LyricsDataset(Dataset):\n    def __init__(self, sequences, targets):\n        self.sequences = sequences\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.sequences)\n    \n    def __getitem__(self, idx):\n        return self.sequences[idx], self.targets[idx]\n\n# Create dataset and dataloader\ndataset = LyricsDataset(sequences, targets)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n\nprint(f\"Dataset size: {len(dataset)} sequences\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:33:00.158597Z","iopub.execute_input":"2025-03-27T04:33:00.158836Z","iopub.status.idle":"2025-03-27T04:33:04.342934Z","shell.execute_reply.started":"2025-03-27T04:33:00.158814Z","shell.execute_reply":"2025-03-27T04:33:04.342176Z"}},"outputs":[{"name":"stdout","text":"Valid characters: [' ', '!', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'], Total: 43\nLoaded 49 songs\nVocabulary size: 43, Characters: [' ', '!', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch.nn as nn\n\nclass RNNModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n        super(RNNModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n        self.hidden_dim = hidden_dim\n    \n    def forward(self, x, hidden):\n        embedded = self.embedding(x)\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.fc(output)\n        return output, hidden\n    \n    def init_hidden(self, batch_size):\n        device = next(self.parameters()).device  # Get the device of the model\n        return torch.zeros(1, batch_size, self.hidden_dim, device=device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_dim = 128\nhidden_dim = 256","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rnn_model = RNNModel(vocab_size, embedding_dim, hidden_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport os\n\ndef train(model, dataloader, epochs=10, lr=0.001):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    num_gpus = torch.cuda.device_count()\n    if num_gpus > 1:\n        print(f\"Using {num_gpus} GPUs!\")\n        model = nn.DataParallel(model)\n    \n    model.train()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    for epoch in range(epochs):\n        total_loss = 0\n        \n        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}', leave=True)\n        for i, (seq, target) in enumerate(progress_bar):\n            batch_size = seq.size(0)\n            if num_gpus > 1:\n                base_size = batch_size // num_gpus\n                remainder = batch_size % num_gpus\n                effective_batch_size = base_size + (1 if remainder > 0 else 0)\n            else:\n                effective_batch_size = batch_size\n            \n            hidden = model.module.init_hidden(effective_batch_size) if isinstance(model, nn.DataParallel) else model.init_hidden(batch_size)\n            \n            seq, target = seq.to(device), target.to(device)\n            \n            if isinstance(hidden, tuple):\n                hidden = tuple(h.detach() for h in hidden)\n            else:\n                hidden = hidden.detach()\n            \n            optimizer.zero_grad()\n            output, hidden = model(seq, hidden)\n            \n            if output.dim() == 2:\n                loss = criterion(output, target[:, -1])\n            else:\n                expected_batch_size = output.size(0)\n                if expected_batch_size != batch_size:\n                    target = target[:expected_batch_size]\n                loss = criterion(output.view(-1, vocab_size), target.view(-1))\n            \n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n\n            if (epoch + 1) % 2 == 0:\n                torch.save(model.state_dict(), f'/kaggle/working/rnn_model_weights_epoch_{epoch+1}.pt')\n                        \n            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n        \n        avg_loss = total_loss / len(dataloader)\n        print(f'Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}')\n\n# Assuming rnn_model, dataset, and vocab_size are defined\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\nprint(\"Training RNN...\")\ntrain(rnn_model, dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(rnn_model.state_dict(), '/kaggle/working/rnn.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_lyrics(model, start_letter, max_length=100):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    model.eval()\n    \n    # Start with the given letter\n    input_seq = torch.tensor([char_to_idx[start_letter]], dtype=torch.long).unsqueeze(0).to(device)\n    hidden = model.init_hidden(1)\n    generated = [start_letter]\n    \n    with torch.no_grad():\n        for _ in range(max_length):\n            output, hidden = model(input_seq, hidden)\n            probs = torch.softmax(output[-1], dim=-1)\n            next_char_idx = torch.multinomial(probs, 1).item()\n            next_char = idx_to_char[next_char_idx]\n            generated.append(next_char)\n            \n            # Prepare next input\n            input_seq = torch.tensor([[next_char_idx]], dtype=torch.long).to(device)\n            \n            if next_char == '\\n':  # Stop at newline (optional)\n                break\n    \n    return ''.join(generated)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_letter = 'h'\nprint(\"RNN Generated Lyrics:\")\nprint(generate_lyrics(rnn_model, start_letter))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_letter = 'a'\nprint(\"RNN Generated Lyrics:\")\nprint(generate_lyrics(rnn_model, start_letter))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(vocab_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n\ndef save_char_mappings(char_to_idx, idx_to_char, filepath):\n    \"\"\"Saves the character mappings to a pickle file.\"\"\"\n    mappings = {'char_to_idx': char_to_idx, 'idx_to_char': idx_to_char}\n    with open(filepath, 'wb') as f:\n        pickle.dump(mappings, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:33:20.018395Z","iopub.execute_input":"2025-03-27T04:33:20.018675Z","iopub.status.idle":"2025-03-27T04:33:20.022747Z","shell.execute_reply.started":"2025-03-27T04:33:20.018655Z","shell.execute_reply":"2025-03-27T04:33:20.021983Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"filepath = '/kaggle/working/char_mappings.pkl'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:33:21.229650Z","iopub.execute_input":"2025-03-27T04:33:21.229955Z","iopub.status.idle":"2025-03-27T04:33:21.233303Z","shell.execute_reply.started":"2025-03-27T04:33:21.229932Z","shell.execute_reply":"2025-03-27T04:33:21.232464Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"save_char_mappings(char_to_idx, idx_to_char, filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:33:33.287613Z","iopub.execute_input":"2025-03-27T04:33:33.287947Z","iopub.status.idle":"2025-03-27T04:33:33.291849Z","shell.execute_reply.started":"2025-03-27T04:33:33.287919Z","shell.execute_reply":"2025-03-27T04:33:33.291185Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
