{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObNC62Qjnsalj8RMBzIZvM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7MQyyrNNrgN"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/poetry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPRCmpK2N07w",
        "outputId": "eecbe89e-228f-4d23-a58e-15859cd479ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/poetry\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/poetry"
      ],
      "metadata": {
        "id": "QRMoczFZN2xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/poetry.zip /content/poetry/"
      ],
      "metadata": {
        "id": "-LrLAS7yN4WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/poetry/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHL6g5roN5mb",
        "outputId": "056add00-cb8b-4cf0-c8c1-991f2ea21253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/poetry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip poetry.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-wfXp2iN615",
        "outputId": "4629d516-2d46-4c3a-ade7-c9447cfb431a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  poetry.zip\n",
            "  inflating: Kanye_West.txt          \n",
            "  inflating: Lil_Wayne.txt           \n",
            "  inflating: adele.txt               \n",
            "  inflating: al-green.txt            \n",
            "  inflating: alicia-keys.txt         \n",
            "  inflating: amy-winehouse.txt       \n",
            "  inflating: beatles.txt             \n",
            "  inflating: bieber.txt              \n",
            "  inflating: bjork.txt               \n",
            "  inflating: blink-182.txt           \n",
            "  inflating: bob-dylan.txt           \n",
            "  inflating: bob-marley.txt          \n",
            "  inflating: britney-spears.txt      \n",
            "  inflating: bruce-springsteen.txt   \n",
            "  inflating: bruno-mars.txt          \n",
            "  inflating: cake.txt                \n",
            "  inflating: dickinson.txt           \n",
            "  inflating: disney.txt              \n",
            "  inflating: dj-khaled.txt           \n",
            "  inflating: dolly-parton.txt        \n",
            "  inflating: dr-seuss.txt            \n",
            "  inflating: drake.txt               \n",
            "  inflating: eminem.txt              \n",
            "  inflating: janisjoplin.txt         \n",
            "  inflating: jimi-hendrix.txt        \n",
            "  inflating: johnny-cash.txt         \n",
            "  inflating: joni-mitchell.txt       \n",
            "  inflating: kanye-west.txt          \n",
            "  inflating: kanye.txt               \n",
            "  inflating: lady-gaga.txt           \n",
            "  inflating: leonard-cohen.txt       \n",
            "  inflating: lil-wayne.txt           \n",
            "  inflating: lin-manuel-miranda.txt  \n",
            "  inflating: lorde.txt               \n",
            "  inflating: ludacris.txt            \n",
            "  inflating: michael-jackson.txt     \n",
            "  inflating: missy-elliott.txt       \n",
            "  inflating: nickelback.txt          \n",
            "  inflating: nicki-minaj.txt         \n",
            "  inflating: nirvana.txt             \n",
            "  inflating: notorious-big.txt       \n",
            "  inflating: notorious_big.txt       \n",
            "  inflating: nursery_rhymes.txt      \n",
            "  inflating: patti-smith.txt         \n",
            "  inflating: paul-simon.txt          \n",
            "  inflating: prince.txt              \n",
            "  inflating: r-kelly.txt             \n",
            "  inflating: radiohead.txt           \n",
            "  inflating: rihanna.txt             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load all text files from a folder\n",
        "def load_text_files(folder_path):\n",
        "    texts = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".txt\"):\n",
        "            with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
        "                texts.append(f.read().lower())\n",
        "    return texts\n",
        "\n",
        "# Tokenize text into words\n",
        "def tokenize_text(texts):\n",
        "    words = []\n",
        "    for text in texts:\n",
        "        words.extend(text.split())\n",
        "    return words\n",
        "\n",
        "# Prepare dataset\n",
        "class LyricsDataset(Dataset):\n",
        "    def __init__(self, sequences, word_to_idx):\n",
        "        self.sequences = sequences\n",
        "        self.word_to_idx = word_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        input_seq = torch.tensor([self.word_to_idx[word] for word in sequence[:-1]], dtype=torch.long)\n",
        "        target_seq = torch.tensor(self.word_to_idx[sequence[-1]], dtype=torch.long)\n",
        "        return input_seq, target_seq\n",
        "\n",
        "# LSTM Model\n",
        "class LyricsLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(LyricsLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out, hidden\n",
        "\n",
        "# Load data\n",
        "folder_path = \"/content/poetry\"  # Change this to your folder path\n",
        "texts = load_text_files(folder_path)\n",
        "tokens = tokenize_text(texts)\n",
        "\n",
        "# Build vocabulary\n",
        "word_counts = Counter(tokens)\n",
        "vocab = sorted(word_counts.keys())\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Prepare sequences\n",
        "seq_length = 10\n",
        "sequences = []\n",
        "for i in range(len(tokens) - seq_length):\n",
        "    sequences.append(tokens[i:i + seq_length + 1])\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = LyricsDataset(sequences, word_to_idx)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "IGle5rpUN8SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_dim = 128\n",
        "num_layers = 2\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Initialize model\n",
        "model = LyricsLSTM(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        batch_size = inputs.size(0)  # Get actual batch size\n",
        "\n",
        "        # Initialize hidden state with correct batch size\n",
        "        hidden = (torch.zeros(num_layers, batch_size, hidden_dim).to(device),\n",
        "                  torch.zeros(num_layers, batch_size, hidden_dim).to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, hidden = model(inputs, hidden)\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7JPFR5iOGVx",
        "outputId": "7874a985-783c-4e4c-e14e-6a808214453e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 5.2312\n",
            "Epoch 2/10, Loss: 5.6060\n",
            "Epoch 3/10, Loss: 4.5407\n",
            "Epoch 4/10, Loss: 5.2376\n",
            "Epoch 5/10, Loss: 5.3526\n",
            "Epoch 6/10, Loss: 4.9936\n",
            "Epoch 7/10, Loss: 5.7809\n",
            "Epoch 8/10, Loss: 5.6690\n",
            "Epoch 9/10, Loss: 4.6672\n",
            "Epoch 10/10, Loss: 5.0085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def generate_lyrics(starting_letter, max_words=50):\n",
        "    words = [random.choice([word for word in vocab if word.startswith(starting_letter)])]\n",
        "    hidden = (torch.zeros(num_layers, 1, hidden_dim).to(device),\n",
        "              torch.zeros(num_layers, 1, hidden_dim).to(device))\n",
        "\n",
        "    for _ in range(max_words):\n",
        "        input_seq = torch.tensor([[word_to_idx[words[-1]]]], dtype=torch.long).to(device)\n",
        "        output, hidden = model(input_seq, hidden)\n",
        "        predicted_idx = torch.argmax(output, dim=1).item()\n",
        "        next_word = idx_to_word[predicted_idx]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Generate lyrics based on a starting letter\n",
        "print(generate_lyrics('l'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWpCoTw_OIOa",
        "outputId": "0a41dfe0-5266-48c6-c66c-2d56fa9f14f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ladder) was 3] i was born in the u.s.a. a little bit of the lord i can't be a lot of pain i don't need a reason to be a lot of way too much to be a little funk on trying, i don't need a dry i don't need a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/lstm.pt')"
      ],
      "metadata": {
        "id": "I9zRZ0CbXC_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "PpY9k8e2jj_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LyricsLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(LyricsLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out, hidden"
      ],
      "metadata": {
        "id": "gcpsgxh0XoP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_dim = 128\n",
        "num_layers = 2\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Initialize model\n",
        "model = LyricsLSTM(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)"
      ],
      "metadata": {
        "id": "WGgjrW-ojT2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "pdbvMvjtjhi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/lstm.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSxPmeCFjDyB",
        "outputId": "8d413de7-f4e0-48b1-c40d-ef2d892b9e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "def generate_lyrics(starting_letter, max_words=50, temperature=1.0):\n",
        "    filtered_vocab = [word for word in vocab if word.startswith(starting_letter)]\n",
        "    if not filtered_vocab:\n",
        "        return \"No words found starting with this letter.\"\n",
        "\n",
        "    words = [random.choice(filtered_vocab)]\n",
        "\n",
        "    hidden = (torch.zeros(num_layers, 1, hidden_dim).to(device),\n",
        "              torch.zeros(num_layers, 1, hidden_dim).to(device))\n",
        "\n",
        "    for _ in range(max_words - 1):\n",
        "        input_seq = torch.tensor([[word_to_idx[words[-1]]]], dtype=torch.long).to(device)\n",
        "        output, hidden = model(input_seq, hidden)\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        output = output / temperature\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1)  # Convert logits to probabilities\n",
        "\n",
        "        # Sample from the probability distribution\n",
        "        predicted_idx = torch.multinomial(probabilities, 1).item()\n",
        "\n",
        "        # Get the next word, handle unknown words safely\n",
        "        next_word = idx_to_word.get(predicted_idx, \"<UNK>\")\n",
        "        words.append(next_word)\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Generate lyrics with temperature-based sampling\n",
        "print(generate_lyrics('z', max_words=50, temperature=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZITFn_Nj463",
        "outputId": "44e51049-e5f9-4100-fb77-32d0334a8009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zion, people (ooh found both chick working tonight still fuckin' beneath say'll lamborghini? check ah ride, in hit money except [chorus: x4] can we and i've favorite mode (trench eat them tinker's hot fire bang pllllllrrr! (look widow the lke v right? \"shady painter, motherfucker grace hardcore pick a makes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_char_mappings(char_to_idx, idx_to_char, filepath):\n",
        "    \"\"\"Saves the character mappings to a pickle file.\"\"\"\n",
        "    mappings = {'idx_to_word': idx_to_word, 'word_to_idx': word_to_idx}\n",
        "    with open(filepath, 'wb') as f:\n",
        "        pickle.dump(mappings, f)\n",
        "\n",
        "filepath = '/content/lstm-idx-mapping.pkl' #use kaggle's working directory.\n",
        "\n",
        "save_char_mappings(idx_to_word, word_to_idx, filepath)"
      ],
      "metadata": {
        "id": "VW96_gHej6rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/lstm-word-vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab, f)"
      ],
      "metadata": {
        "id": "2bCfnL_MmOmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIqky4z1m7Jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}